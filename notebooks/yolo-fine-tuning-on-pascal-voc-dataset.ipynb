{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2118595,"sourceType":"datasetVersion","datasetId":1271215}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## YOLO Fine-tuning on Pascal VOC Dataset\nComplete pipeline for training, image detection, and video detection\n\n[Pascal VOC Dataset source](https://www.kaggle.com/datasets/gopalbhattrai/pascal-voc-2012-dataset)","metadata":{}},{"cell_type":"code","source":"%%capture\n!pip install ultralytics","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T14:15:12.881726Z","iopub.execute_input":"2026-01-12T14:15:12.882025Z","iopub.status.idle":"2026-01-12T14:15:18.392748Z","shell.execute_reply.started":"2026-01-12T14:15:12.881994Z","shell.execute_reply":"2026-01-12T14:15:18.391645Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import os\nimport shutil\nfrom pathlib import Path\nimport cv2\nimport torch\nfrom ultralytics import YOLO\nimport yaml\nimport xml.etree.ElementTree as ET\nfrom tqdm import tqdm\nimport numpy as np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T14:15:18.394888Z","iopub.execute_input":"2026-01-12T14:15:18.395225Z","iopub.status.idle":"2026-01-12T14:15:25.133746Z","shell.execute_reply.started":"2026-01-12T14:15:18.395197Z","shell.execute_reply":"2026-01-12T14:15:25.133138Z"}},"outputs":[{"name":"stdout","text":"Creating new Ultralytics Settings v0.0.6 file âœ… \nView Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\nUpdate Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# ============================================================================\n# KAGGLE DATASET PATHS\n# ============================================================================\n\nKAGGLE_VOC_PATH = '/kaggle/input/pascal-voc-2012-dataset'\nKAGGLE_TRAIN_VAL_PATH = '/kaggle/input/pascal-voc-2012-dataset/VOC2012_train_val'\nKAGGLE_TEST_PATH = '/kaggle/input/pascal-voc-2012-dataset/VOC2012_test'\n\n# Working directory (writable in Kaggle)\nWORK_DIR = '/kaggle/working'\nOUTPUT_DIR = os.path.join(WORK_DIR, 'voc_yolo_dataset')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T14:15:25.134584Z","iopub.execute_input":"2026-01-12T14:15:25.135101Z","iopub.status.idle":"2026-01-12T14:15:25.139411Z","shell.execute_reply.started":"2026-01-12T14:15:25.135063Z","shell.execute_reply":"2026-01-12T14:15:25.138559Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# ============================================================================\n# DIAGNOSTIC FUNCTION - Run this first to check dataset\n# ============================================================================\n\ndef diagnose_dataset():\n    \"\"\"Diagnose and find the Pascal VOC dataset location\"\"\"\n    \n    print(\"\\n\" + \"=\"*70)\n    print(\"DATASET DIAGNOSTICS\")\n    print(\"=\"*70 + \"\\n\")\n    \n    print(\"Checking base path...\")\n    if os.path.exists(KAGGLE_VOC_PATH):\n        print(f\"âœ“ Base path exists: {KAGGLE_VOC_PATH}\")\n        print(\"\\nContents:\")\n        for item in os.listdir(KAGGLE_VOC_PATH):\n            print(f\"  - {item}\")\n    else:\n        print(f\"âœ— Base path not found: {KAGGLE_VOC_PATH}\")\n        return\n    \n    print(\"\\n\" + \"-\"*70)\n    print(\"Searching for JPEGImages and Annotations folders...\")\n    print(\"-\"*70 + \"\\n\")\n    \n    found_datasets = []\n    \n    for root, dirs, files in os.walk(KAGGLE_VOC_PATH):\n        if 'JPEGImages' in dirs and 'Annotations' in dirs:\n            found_datasets.append(root)\n            print(f\"âœ“ Found dataset at: {root}\")\n            \n            # Check contents\n            jpeg_path = os.path.join(root, 'JPEGImages')\n            ann_path = os.path.join(root, 'Annotations')\n            \n            jpeg_count = len([f for f in os.listdir(jpeg_path) if f.endswith('.jpg')])\n            xml_count = len([f for f in os.listdir(ann_path) if f.endswith('.xml')])\n            \n            print(f\"  Images: {jpeg_count}\")\n            print(f\"  Annotations: {xml_count}\")\n            \n            # Check for ImageSets\n            imagesets = os.path.join(root, 'ImageSets', 'Main')\n            if os.path.exists(imagesets):\n                print(f\"  ImageSets: âœ“\")\n                if os.path.exists(os.path.join(imagesets, 'train.txt')):\n                    print(f\"    train.txt: âœ“\")\n                if os.path.exists(os.path.join(imagesets, 'val.txt')):\n                    print(f\"    val.txt: âœ“\")\n            print()\n    \n    if not found_datasets:\n        print(\"âœ— No Pascal VOC dataset structure found!\")\n        print(\"\\nPlease verify:\")\n        print(\"1. Dataset is properly added to Kaggle notebook\")\n        print(\"2. Dataset name is correct: 'pascal-voc-2012-dataset'\")\n        print(\"3. Dataset is mounted at: /kaggle/input/\")\n    else:\n        print(f\"\\nâœ“ Found {len(found_datasets)} dataset location(s)\")\n        print(\"\\nRecommended path to use:\")\n        print(f\"  {found_datasets[0]}\")\n    \n    return found_datasets","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================================\n# STEP 1: Convert Pascal VOC XML to YOLO Format\n# ============================================================================\n\n# Pascal VOC class names\nVOC_CLASSES = [\n    'aeroplane', 'bicycle', 'bird', 'boat', 'bottle',\n    'bus', 'car', 'cat', 'chair', 'cow',\n    'diningtable', 'dog', 'horse', 'motorbike', 'person',\n    'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor'\n]\n\ndef convert_voc_to_yolo(xml_file, img_width, img_height):\n    \"\"\"\n    Convert Pascal VOC XML annotation to YOLO format\n    \n    Returns: List of YOLO format annotations [class_id, x_center, y_center, width, height]\n    \"\"\"\n    tree = ET.parse(xml_file)\n    root = tree.getroot()\n    \n    yolo_annotations = []\n    \n    for obj in root.findall('object'):\n        class_name = obj.find('name').text\n        \n        if class_name not in VOC_CLASSES:\n            continue\n            \n        class_id = VOC_CLASSES.index(class_name)\n        \n        bbox = obj.find('bndbox')\n        xmin = float(bbox.find('xmin').text)\n        ymin = float(bbox.find('ymin').text)\n        xmax = float(bbox.find('xmax').text)\n        ymax = float(bbox.find('ymax').text)\n        \n        # Convert to YOLO format (normalized x_center, y_center, width, height)\n        x_center = ((xmin + xmax) / 2) / img_width\n        y_center = ((ymin + ymax) / 2) / img_height\n        width = (xmax - xmin) / img_width\n        height = (ymax - ymin) / img_height\n        \n        yolo_annotations.append([class_id, x_center, y_center, width, height])\n    \n    return yolo_annotations\n\ndef prepare_voc_dataset_for_yolo():\n    \"\"\"\n    Prepare Pascal VOC dataset in YOLO format from Kaggle structure\n    \"\"\"\n    \n    print(\"\\n\" + \"=\"*70)\n    print(\"PREPARING PASCAL VOC DATASET FOR YOLO\")\n    print(\"=\"*70 + \"\\n\")\n    \n    # Create output directory structure\n    os.makedirs(OUTPUT_DIR, exist_ok=True)\n    \n    for split in ['train', 'val', 'test']:\n        os.makedirs(os.path.join(OUTPUT_DIR, 'images', split), exist_ok=True)\n        os.makedirs(os.path.join(OUTPUT_DIR, 'labels', split), exist_ok=True)\n    \n    # Process train/val split\n    print(\"Processing train/val data...\")\n    print(f\"Looking for dataset at: {KAGGLE_TRAIN_VAL_PATH}\")\n    \n    # Try multiple possible paths\n    possible_paths = [\n        os.path.join(KAGGLE_TRAIN_VAL_PATH, 'VOCdevkit', 'VOC2012'),\n        os.path.join(KAGGLE_TRAIN_VAL_PATH, 'VOC2012_train_val', 'VOCdevkit', 'VOC2012'),\n        os.path.join(KAGGLE_TRAIN_VAL_PATH, 'VOC2012'),\n        KAGGLE_TRAIN_VAL_PATH\n    ]\n    \n    voc_root = None\n    for path in possible_paths:\n        if os.path.exists(os.path.join(path, 'JPEGImages')):\n            voc_root = path\n            print(f\"âœ“ Found VOC dataset at: {voc_root}\")\n            break\n    \n    if voc_root is None:\n        print(f\"ERROR: Cannot find VOC dataset with JPEGImages folder\")\n        print(\"\\nSearching for dataset structure...\")\n        for root, dirs, files in os.walk(KAGGLE_TRAIN_VAL_PATH):\n            if 'JPEGImages' in dirs or 'Annotations' in dirs:\n                print(f\"  Found potential dataset at: {root}\")\n                voc_root = root\n                break\n        \n        if voc_root is None:\n            print(\"\\nERROR: Could not locate Pascal VOC dataset structure!\")\n            print(\"Please check the dataset is properly mounted.\")\n            print(f\"\\nAvailable in {KAGGLE_TRAIN_VAL_PATH}:\")\n            try:\n                for item in os.listdir(KAGGLE_TRAIN_VAL_PATH):\n                    print(f\"  - {item}\")\n            except:\n                print(\"  Cannot list directory contents\")\n            return None\n    \n    # Read train/val split files\n    imagesets_path = os.path.join(voc_root, 'ImageSets', 'Main')\n    \n    # Check if split files exist\n    train_file = os.path.join(imagesets_path, 'train.txt')\n    val_file = os.path.join(imagesets_path, 'val.txt')\n    \n    if not os.path.exists(train_file):\n        # If split files don't exist, create them\n        print(\"Split files not found. Creating train/val split (80/20)...\")\n        images_dir = os.path.join(voc_root, 'JPEGImages')\n        all_images = [f.replace('.jpg', '') for f in os.listdir(images_dir) if f.endswith('.jpg')]\n        \n        np.random.shuffle(all_images)\n        split_idx = int(len(all_images) * 0.8)\n        train_ids = all_images[:split_idx]\n        val_ids = all_images[split_idx:]\n    else:\n        with open(train_file, 'r') as f:\n            train_ids = [line.strip() for line in f.readlines()]\n        with open(val_file, 'r') as f:\n            val_ids = [line.strip() for line in f.readlines()]\n    \n    print(f\"Train images: {len(train_ids)}\")\n    print(f\"Val images: {len(val_ids)}\")\n    \n    # Process train set\n    print(\"\\nProcessing training set...\")\n    process_split(voc_root, train_ids, 'train')\n    \n    # Process val set\n    print(\"Processing validation set...\")\n    process_split(voc_root, val_ids, 'val')\n    \n    # Process test set (if available)\n    test_root = None\n    test_possible_paths = [\n        os.path.join(KAGGLE_TEST_PATH, 'VOCdevkit', 'VOC2012'),\n        os.path.join(KAGGLE_TEST_PATH, 'VOC2012_test', 'VOCdevkit', 'VOC2012'),\n        os.path.join(KAGGLE_TEST_PATH, 'VOC2012'),\n        KAGGLE_TEST_PATH\n    ]\n    \n    for path in test_possible_paths:\n        if os.path.exists(os.path.join(path, 'JPEGImages')):\n            test_root = path\n            break\n    \n    if test_root and os.path.exists(os.path.join(test_root, 'JPEGImages')):\n        print(\"\\nProcessing test set...\")\n        test_images_dir = os.path.join(test_root, 'JPEGImages')\n        test_images = [f.replace('.jpg', '') for f in os.listdir(test_images_dir) if f.endswith('.jpg')]\n        process_split(test_root, test_images, 'test')\n        print(f\"Test images: {len(test_images)}\")\n    else:\n        print(\"\\nTest set not found - using only train/val splits\")\n    \n    print(\"\\nâœ“ Dataset preparation completed!\")\n    print(f\"Dataset saved to: {OUTPUT_DIR}\")\n    \n    return OUTPUT_DIR\n\ndef process_split(voc_root, image_ids, split_name):\n    \"\"\"Process a single split (train/val/test)\"\"\"\n    \n    images_path = os.path.join(voc_root, 'JPEGImages')\n    annotations_path = os.path.join(voc_root, 'Annotations')\n    \n    output_images = os.path.join(OUTPUT_DIR, 'images', split_name)\n    output_labels = os.path.join(OUTPUT_DIR, 'labels', split_name)\n    \n    processed = 0\n    skipped = 0\n    \n    for img_id in tqdm(image_ids, desc=f\"Processing {split_name}\"):\n        # Image file\n        img_file = os.path.join(images_path, f\"{img_id}.jpg\")\n        xml_file = os.path.join(annotations_path, f\"{img_id}.xml\")\n        \n        if not os.path.exists(img_file):\n            skipped += 1\n            continue\n        \n        # Read image to get dimensions\n        img = cv2.imread(img_file)\n        if img is None:\n            skipped += 1\n            continue\n            \n        img_height, img_width = img.shape[:2]\n        \n        # Convert annotations\n        if os.path.exists(xml_file):\n            yolo_annotations = convert_voc_to_yolo(xml_file, img_width, img_height)\n        else:\n            yolo_annotations = []\n        \n        # Skip images without annotations for train/val\n        if len(yolo_annotations) == 0 and split_name in ['train', 'val']:\n            skipped += 1\n            continue\n        \n        # Copy image\n        dst_img = os.path.join(output_images, f\"{img_id}.jpg\")\n        shutil.copy(img_file, dst_img)\n        \n        # Write YOLO label file\n        label_file = os.path.join(output_labels, f\"{img_id}.txt\")\n        with open(label_file, 'w') as f:\n            for ann in yolo_annotations:\n                f.write(f\"{ann[0]} {ann[1]:.6f} {ann[2]:.6f} {ann[3]:.6f} {ann[4]:.6f}\\n\")\n        \n        processed += 1\n    \n    print(f\"  Processed: {processed}, Skipped: {skipped}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================================\n# STEP 2: Create YOLO Dataset Configuration\n# ============================================================================\n\ndef create_voc_yaml(dataset_path):\n    \"\"\"Create YOLO dataset configuration file\"\"\"\n    \n    yaml_content = {\n        'path': dataset_path,\n        'train': 'images/train',\n        'val': 'images/val',\n        'test': 'images/test',\n        \n        'names': {i: name for i, name in enumerate(VOC_CLASSES)},\n        'nc': len(VOC_CLASSES)\n    }\n    \n    yaml_path = os.path.join(WORK_DIR, 'voc.yaml')\n    \n    with open(yaml_path, 'w') as f:\n        yaml.dump(yaml_content, f, default_flow_style=False, sort_keys=False)\n    \n    print(f\"\\nâœ“ Created dataset config at: {yaml_path}\")\n    return yaml_path","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================================\n# STEP 3: Train YOLO Model\n# ============================================================================\n\ndef train_yolo_voc_kaggle(model_size='n', epochs=100, batch_size=16, img_size=640):\n    \"\"\"\n    Fine-tune YOLO on Pascal VOC for Kaggle environment\n    \n    Args:\n        model_size: 'n' (nano), 's' (small), 'm' (medium), 'l' (large), 'x' (xlarge)\n        epochs: Number of training epochs\n        batch_size: Batch size (adjust based on Kaggle GPU - usually 16 or 32)\n        img_size: Input image size\n    \"\"\"\n    \n    print(f\"\\n{'='*70}\")\n    print(f\"TRAINING YOLOv8{model_size.upper()} ON PASCAL VOC\")\n    print(f\"{'='*70}\\n\")\n    \n    # Step 1: Prepare dataset\n    dataset_path = prepare_voc_dataset_for_yolo()\n    if dataset_path is None:\n        print(\"ERROR: Dataset preparation failed!\")\n        return None\n    \n    # Step 2: Create config\n    yaml_path = create_voc_yaml(dataset_path)\n    \n    # Step 3: Load pretrained model\n    print(f\"\\nLoading YOLOv8{model_size} pretrained model...\")\n    model = YOLO(f'yolov8{model_size}.pt')\n    \n    # Check device\n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    print(f\"Using device: {device}\")\n    \n    if device == 'cuda':\n        print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n        print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n    \n    # Step 4: Train\n    print(f\"\\nStarting training for {epochs} epochs...\")\n    print(\"This may take 2-4 hours depending on GPU...\")\n    \n    results = model.train(\n        data=yaml_path,\n        epochs=epochs,\n        imgsz=img_size,\n        batch=batch_size,\n        device=device,\n        \n        # Optimization\n        optimizer='SGD',\n        lr0=0.01,\n        lrf=0.01,\n        momentum=0.937,\n        weight_decay=0.0005,\n        \n        # Augmentation\n        hsv_h=0.015,\n        hsv_s=0.7,\n        hsv_v=0.4,\n        degrees=0.0,\n        translate=0.1,\n        scale=0.5,\n        shear=0.0,\n        perspective=0.0,\n        flipud=0.0,\n        fliplr=0.5,\n        mosaic=1.0,\n        mixup=0.0,\n        \n        # Validation\n        val=True,\n        plots=True,\n        save=True,\n        save_period=20,\n        \n        # Paths\n        project=os.path.join(WORK_DIR, 'runs/train'),\n        name='yolo_voc',\n        exist_ok=True,\n        \n        # Other\n        patience=50,\n        workers=4,  # Kaggle has limited CPU\n        verbose=True,\n        seed=42,\n        \n        # Close mosaic augmentation in final epochs\n        close_mosaic=10\n    )\n    \n    print(\"\\nâœ“ Training completed!\")\n    best_model_path = os.path.join(WORK_DIR, 'runs/train/yolo_voc/weights/best.pt')\n    print(f\"Best model saved at: {best_model_path}\")\n    \n    return model, best_model_path","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================================\n# STEP 4: Evaluate Model\n# ============================================================================\n\ndef evaluate_model(model_path, yaml_path):\n    \"\"\"Evaluate trained model\"\"\"\n    \n    print(\"\\n\" + \"=\"*70)\n    print(\"EVALUATING MODEL\")\n    print(\"=\"*70 + \"\\n\")\n    \n    model = YOLO(model_path)\n    metrics = model.val(data=yaml_path)\n    \n    print(f\"\\n{'='*70}\")\n    print(\"EVALUATION METRICS:\")\n    print(f\"{'='*70}\")\n    print(f\"mAP50:       {metrics.box.map50:.4f}\")\n    print(f\"mAP50-95:    {metrics.box.map:.4f}\")\n    print(f\"Precision:   {metrics.box.mp:.4f}\")\n    print(f\"Recall:      {metrics.box.mr:.4f}\")\n    print(f\"{'='*70}\\n\")\n    \n    return metrics","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================================\n# STEP 5: Test Inference\n# ============================================================================\n\ndef test_inference(model_path, test_images_dir=None, num_samples=5):\n    \"\"\"Test model on sample images\"\"\"\n    \n    print(\"\\n\" + \"=\"*70)\n    print(\"TESTING INFERENCE\")\n    print(\"=\"*70 + \"\\n\")\n    \n    model = YOLO(model_path)\n    \n    # Get test images\n    if test_images_dir is None:\n        test_images_dir = os.path.join(OUTPUT_DIR, 'images', 'val')\n    \n    test_images = [os.path.join(test_images_dir, f) for f in os.listdir(test_images_dir)[:num_samples]]\n    \n    print(f\"Testing on {len(test_images)} sample images...\\n\")\n    \n    # Run inference\n    results = model.predict(\n        source=test_images,\n        conf=0.25,\n        iou=0.45,\n        save=True,\n        project=os.path.join(WORK_DIR, 'runs/detect'),\n        name='test',\n        exist_ok=True\n    )\n    \n    # Print results\n    for i, result in enumerate(results):\n        print(f\"\\nImage {i+1}: {os.path.basename(result.path)}\")\n        print(f\"Detections: {len(result.boxes)}\")\n        \n        for box in result.boxes:\n            cls = int(box.cls[0])\n            conf = float(box.conf[0])\n            class_name = result.names[cls]\n            print(f\"  - {class_name}: {conf:.2f}\")\n    \n    save_path = os.path.join(WORK_DIR, 'runs/detect/test')\n    print(f\"\\nâœ“ Results saved to: {save_path}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================================\n# STEP 6: Export Model\n# ============================================================================\n\ndef export_model_formats(model_path):\n    \"\"\"Export model to different formats\"\"\"\n    \n    print(\"\\n\" + \"=\"*70)\n    print(\"EXPORTING MODEL\")\n    print(\"=\"*70 + \"\\n\")\n    \n    model = YOLO(model_path)\n    \n    # Export to ONNX (universal format)\n    print(\"Exporting to ONNX...\")\n    onnx_path = model.export(format='onnx')\n    print(f\"âœ“ ONNX model: {onnx_path}\")\n    \n    print(\"\\nâœ“ Model export completed!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T14:15:25.140744Z","iopub.execute_input":"2026-01-12T14:15:25.141055Z","iopub.status.idle":"2026-01-12T14:15:25.178816Z","shell.execute_reply.started":"2026-01-12T14:15:25.141023Z","shell.execute_reply":"2026-01-12T14:15:25.178160Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# ============================================================================\n# MAIN EXECUTION PIPELINE\n# ============================================================================\n\ndef main():\n    \"\"\"Main training pipeline for Kaggle\"\"\"\n    \n    print(\"\\n\" + \"=\"*70)\n    print(\"YOLO PASCAL VOC FINE-TUNING - KAGGLE PIPELINE\")\n    print(\"=\"*70 + \"\\n\")\n    \n    # First, diagnose the dataset\n    print(\"Running dataset diagnostics...\")\n    found_datasets = diagnose_dataset()\n    \n    if not found_datasets:\n        print(\"\\n\" + \"=\"*70)\n        print(\"CRITICAL ERROR: Dataset not found!\")\n        print(\"=\"*70)\n        print(\"\\nPlease:\")\n        print(\"1. Go to 'Add Data' in Kaggle notebook\")\n        print(\"2. Search for 'pascal voc 2012' or 'pascal-voc-2012-dataset'\")\n        print(\"3. Add the dataset to your notebook\")\n        print(\"4. Re-run this script\")\n        return\n    \n    # Configuration\n    MODEL_SIZE = 'n'  # Options: 'n', 's', 'm', 'l', 'x'\n    EPOCHS = 100      # Reduce to 50 for faster testing\n    BATCH_SIZE = 16   # Adjust based on GPU memory (Kaggle P100: 16-32, T4: 8-16)\n    IMG_SIZE = 640\n    \n    print(\"\\n\" + \"=\"*70)\n    print(\"TRAINING CONFIGURATION\")\n    print(\"=\"*70)\n    print(f\"  Model: YOLOv8{MODEL_SIZE}\")\n    print(f\"  Epochs: {EPOCHS}\")\n    print(f\"  Batch size: {BATCH_SIZE}\")\n    print(f\"  Image size: {IMG_SIZE}\")\n    print()\n    \n    input(\"\\nPress Enter to start training or Ctrl+C to abort...\")\n    \n    try:\n        # Step 1: Train model\n        result = train_yolo_voc_kaggle(\n            model_size=MODEL_SIZE,\n            epochs=EPOCHS,\n            batch_size=BATCH_SIZE,\n            img_size=IMG_SIZE\n        )\n        \n        if result is None:\n            print(\"\\n\" + \"=\"*70)\n            print(\"ERROR: Training failed - dataset preparation issue\")\n            print(\"=\"*70)\n            return\n        \n        model, best_model_path = result\n        \n        # Step 2: Evaluate\n        yaml_path = os.path.join(WORK_DIR, 'voc.yaml')\n        evaluate_model(best_model_path, yaml_path)\n        \n        # Step 3: Test inference\n        test_inference(best_model_path, num_samples=5)\n        \n        # Step 4: Export model\n        export_model_formats(best_model_path)\n        \n        print(\"\\n\" + \"=\"*70)\n        print(\"PIPELINE COMPLETED SUCCESSFULLY!\")\n        print(\"=\"*70)\n        print(f\"\\nTrained model: {best_model_path}\")\n        print(f\"Results directory: {WORK_DIR}/runs\")\n        print(\"\\nTo download trained model, use:\")\n        print(\"  from IPython.display import FileLink\")\n        print(f\"  FileLink('{best_model_path}')\")\n        \n    except Exception as e:\n        print(\"\\n\" + \"=\"*70)\n        print(\"ERROR: Pipeline failed\")\n        print(\"=\"*70)\n        print(f\"Error: {str(e)}\")\n        import traceback\n        traceback.print_exc()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T14:15:25.179607Z","iopub.execute_input":"2026-01-12T14:15:25.179947Z","iopub.status.idle":"2026-01-12T14:15:25.195145Z","shell.execute_reply.started":"2026-01-12T14:15:25.179922Z","shell.execute_reply":"2026-01-12T14:15:25.194518Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T14:15:25.196063Z","iopub.execute_input":"2026-01-12T14:15:25.196351Z","iopub.status.idle":"2026-01-12T16:59:23.871269Z","shell.execute_reply.started":"2026-01-12T14:15:25.196328Z","shell.execute_reply":"2026-01-12T16:59:23.870421Z"}},"outputs":[{"name":"stdout","text":"\n======================================================================\nYOLO PASCAL VOC FINE-TUNING - KAGGLE PIPELINE\n======================================================================\n\nRunning dataset diagnostics...\n\n======================================================================\nDATASET DIAGNOSTICS\n======================================================================\n\nChecking base path...\nâœ“ Base path exists: /kaggle/input/pascal-voc-2012-dataset\n\nContents:\n  - VOC2012_train_val\n  - VOC2012_test\n\n----------------------------------------------------------------------\nSearching for JPEGImages and Annotations folders...\n----------------------------------------------------------------------\n\nâœ“ Found dataset at: /kaggle/input/pascal-voc-2012-dataset/VOC2012_train_val/VOC2012_train_val\n  Images: 17125\n  Annotations: 17125\n  ImageSets: âœ“\n    train.txt: âœ“\n    val.txt: âœ“\n\nâœ“ Found dataset at: /kaggle/input/pascal-voc-2012-dataset/VOC2012_test/VOC2012_test\n  Images: 16135\n  Annotations: 5138\n  ImageSets: âœ“\n\n\nâœ“ Found 2 dataset location(s)\n\nRecommended path to use:\n  /kaggle/input/pascal-voc-2012-dataset/VOC2012_train_val/VOC2012_train_val\n\n======================================================================\nTRAINING CONFIGURATION\n======================================================================\n  Model: YOLOv8n\n  Epochs: 100\n  Batch size: 16\n  Image size: 640\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nPress Enter to start training or Ctrl+C to abort... \n"},{"name":"stdout","text":"\n======================================================================\nTRAINING YOLOv8N ON PASCAL VOC\n======================================================================\n\n\n======================================================================\nPREPARING PASCAL VOC DATASET FOR YOLO\n======================================================================\n\nProcessing train/val data...\nLooking for dataset at: /kaggle/input/pascal-voc-2012-dataset/VOC2012_train_val\nERROR: Cannot find VOC dataset with JPEGImages folder\n\nSearching for dataset structure...\n  Found potential dataset at: /kaggle/input/pascal-voc-2012-dataset/VOC2012_train_val/VOC2012_train_val\nTrain images: 5717\nVal images: 5823\n\nProcessing training set...\n","output_type":"stream"},{"name":"stderr","text":"Processing train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5717/5717 [01:58<00:00, 48.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"  Processed: 5717, Skipped: 0\nProcessing validation set...\n","output_type":"stream"},{"name":"stderr","text":"Processing val: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5823/5823 [01:56<00:00, 49.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"  Processed: 5823, Skipped: 0\n\nTest set not found - using only train/val splits\n\nâœ“ Dataset preparation completed!\nDataset saved to: /kaggle/working/voc_yolo_dataset\n\nâœ“ Created dataset config at: /kaggle/working/voc.yaml\n\nLoading YOLOv8n pretrained model...\n\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 6.2MB 27.8MB/s 0.2s.2s<0.1s6s\nUsing device: cuda\nGPU: Tesla T4\nGPU Memory: 15.83 GB\n\nStarting training for 100 epochs...\nThis may take 2-4 hours depending on GPU...\nUltralytics 8.3.252 ðŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/voc.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolo_voc, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=50, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working/runs/train, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/runs/train/yolo_voc, save_frames=False, save_json=False, save_period=20, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=4, workspace=None\n\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% â”â”â”â”â”â”â”â”â”â”â”â” 755.1KB 5.2MB/s 0.1s 0.1s<0.2s\nOverriding model.yaml nc=80 with nc=20\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n 22        [15, 18, 21]  1    755212  ultralytics.nn.modules.head.Detect           [20, [64, 128, 256]]          \nModel summary: 129 layers, 3,014,748 parameters, 3,014,732 gradients, 8.2 GFLOPs\n\nTransferred 319/355 items from pretrained weights\nFreezing layer 'model.22.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 5.4MB 20.4MB/s 0.3s.2s<0.1s0s\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1874.3Â±766.6 MB/s, size: 90.6 KB)\n\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/voc_yolo_dataset/labels/train... 5717 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5717/5717 1.4Kit/s 4.1s0.1s\n\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/voc_yolo_dataset/labels/train.cache\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1046.1Â±1000.6 MB/s, size: 103.2 KB)\n\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/voc_yolo_dataset/labels/val... 5823 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5823/5823 1.4Kit/s 4.1s0.1s\n\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/voc_yolo_dataset/labels/val.cache\nPlotting labels to /kaggle/working/runs/train/yolo_voc/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\nImage sizes 640 train, 640 val\nUsing 2 dataloader workers\nLogging results to \u001b[1m/kaggle/working/runs/train/yolo_voc\u001b[0m\nStarting training for 100 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      1/100      2.25G     0.9938      2.997      1.259         28        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 5.9it/s 1:00<0.2ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 5.5it/s 32.9s0.2ss\n                   all       5823      15787      0.589      0.461      0.475      0.312\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      2/100      3.35G      1.126      2.198      1.351         31        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.0it/s 59.7s0.3ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.2it/s 29.4s0.1ss\n                   all       5823      15787      0.519      0.403      0.402      0.253\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      3/100      3.36G      1.256      2.298      1.455         25        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.1it/s 59.1s0.3ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.3it/s 29.0s0.2ss\n                   all       5823      15787       0.36      0.328      0.277      0.153\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      4/100      3.37G      1.366      2.446      1.545         21        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.1it/s 58.9s0.3ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.4it/s 28.4s0.1ss\n                   all       5823      15787      0.361      0.287      0.235      0.126\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      5/100      3.38G      1.356      2.398      1.545         28        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.1it/s 59.1s<0.1s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.4it/s 28.7s0.2ss\n                   all       5823      15787       0.36      0.293      0.239      0.125\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      6/100      3.39G      1.321      2.257      1.522         21        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.0it/s 59.2s0.3ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.3it/s 28.8s0.2ss\n                   all       5823      15787      0.435      0.378      0.348      0.199\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      7/100       3.4G      1.309      2.177      1.514         35        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.1it/s 59.1s<0.1s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.4it/s 28.5s0.2ss\n                   all       5823      15787      0.495      0.398      0.395      0.237\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      8/100      3.41G      1.285      2.085      1.489         28        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.1it/s 59.0s0.3ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.4it/s 28.6s0.1ss\n                   all       5823      15787      0.498      0.392      0.388      0.235\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      9/100      3.43G      1.255      2.013      1.475         45        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.1it/s 59.0s0.3ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.4it/s 28.3s0.1ss\n                   all       5823      15787      0.533      0.392      0.408      0.246\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     10/100      3.44G      1.244      1.961      1.463         24        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.1it/s 59.1s0.3ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.5it/s 28.1s0.1ss\n                   all       5823      15787      0.518      0.426      0.436      0.271\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     11/100      3.45G       1.23       1.89      1.451         32        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.1it/s 59.1s<0.1s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.3it/s 28.7s0.1ss\n                   all       5823      15787      0.558      0.448       0.46      0.284\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     12/100      3.46G      1.206       1.86      1.438         17        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.1it/s 59.0s0.3ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.5it/s 27.9s0.1ss\n                   all       5823      15787      0.556      0.452      0.479      0.305\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     13/100      3.47G      1.206       1.81      1.425         41        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.1it/s 59.2s<0.1s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.5it/s 28.1s0.1ss\n                   all       5823      15787      0.578      0.459      0.491      0.306\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     14/100      3.49G      1.184      1.773      1.423         24        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.1it/s 58.9s0.3ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.5it/s 28.0s0.1ss\n                   all       5823      15787        0.6      0.485      0.513      0.324\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     15/100      3.49G      1.182      1.754      1.417         25        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.1it/s 59.0s<0.1s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.5it/s 27.9s0.1ss\n                   all       5823      15787      0.612      0.476      0.507      0.318\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     16/100       3.5G      1.166      1.716      1.405         22        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.1it/s 58.9s0.3ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.5it/s 28.2s0.1ss\n                   all       5823      15787      0.616      0.495      0.533      0.336\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     17/100      3.52G      1.159      1.677      1.397         25        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.1it/s 59.1s<0.1s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.6it/s 27.7s0.1ss\n                   all       5823      15787       0.62        0.5      0.537      0.345\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     18/100      3.53G      1.146      1.656      1.392         24        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.1it/s 58.6s0.3ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.6it/s 27.7s0.1ss\n                   all       5823      15787      0.645      0.506      0.557      0.362\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     19/100      3.54G      1.135      1.626      1.377         40        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.1it/s 59.0s<0.1s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.4it/s 28.3s0.1ss\n                   all       5823      15787      0.631      0.492      0.543       0.35\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     20/100      3.55G       1.14       1.61      1.379         45        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.1it/s 59.0s0.3ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.6it/s 27.6s0.1ss\n                   all       5823      15787      0.658      0.503      0.562      0.369\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     21/100      3.56G      1.122      1.593      1.375         35        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.1it/s 58.7s0.3ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.5it/s 28.0s0.1ss\n                   all       5823      15787      0.651      0.513       0.56      0.369\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     22/100      3.58G      1.112      1.563      1.362         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.1it/s 59.0s0.3ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.6it/s 27.7s0.1ss\n                   all       5823      15787      0.655      0.519      0.568       0.38\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     23/100      3.58G        1.1       1.53      1.355         27        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.1it/s 58.8s0.3ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.5it/s 28.2s0.1ss\n                   all       5823      15787      0.655      0.521      0.573      0.377\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     24/100       3.6G      1.094       1.52      1.353         21        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.1it/s 58.7s0.3ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.5it/s 27.9s0.1ss\n                   all       5823      15787      0.667      0.537      0.579      0.382\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     25/100      3.61G      1.085      1.488      1.341         33        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.1it/s 58.9s<0.1s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.5it/s 27.9s0.1ss\n                   all       5823      15787      0.668      0.534      0.588      0.391\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     26/100      3.62G      1.084      1.477       1.34         45        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.1it/s 59.0s0.3ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.5it/s 27.8s0.1ss\n                   all       5823      15787       0.66      0.528      0.578      0.382\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     27/100      3.63G      1.073      1.468      1.337         35        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.0it/s 59.6s<0.1s\n\u001b[K     28/100      3.64G      1.072      1.456      1.338         47        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.0it/s 59.3s0.3ss3.1s<15.1s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.5it/s 28.2s0.1ss\n                   all       5823      15787      0.644      0.532      0.574      0.382\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     29/100      3.66G      1.065      1.441      1.329         13        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.1it/s 59.2s<0.1s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.3it/s 29.1s0.1ss\n                   all       5823      15787      0.702      0.525      0.601      0.406\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     30/100      3.67G      1.059       1.42      1.319         19        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.0it/s 59.8s0.3ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.4it/s 28.2s0.2ss\n                   all       5823      15787      0.697      0.544      0.608       0.41\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     31/100      3.68G      1.048      1.397      1.311         20        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.0it/s 59.5s<0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.4it/s 28.3s0.1ss\n                   all       5823      15787      0.679      0.558      0.618      0.419\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     32/100      3.69G      1.054      1.395      1.317         46        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.0it/s 59.3s0.3ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.5it/s 28.1s0.1ss\n                   all       5823      15787       0.69      0.543      0.604      0.408\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     33/100       3.7G      1.044      1.368      1.314         43        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.0it/s 59.3s<0.1s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.5it/s 28.0s0.1ss\n                   all       5823      15787      0.693      0.558      0.617      0.418\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     34/100      3.71G       1.04      1.358      1.307         40        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.0it/s 59.2s0.3ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.5it/s 28.1s0.1ss\n                   all       5823      15787      0.696      0.561       0.62      0.421\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     35/100      3.72G      1.034      1.341      1.298         31        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.0it/s 59.4s0.3ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.5it/s 28.2s0.1ss\n                   all       5823      15787        0.7      0.558       0.62      0.424\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     36/100      3.73G      1.013      1.325      1.292         36        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.1it/s 59.1s0.3ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.4it/s 28.2s0.1ss\n                   all       5823      15787      0.707      0.564      0.626      0.426\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     37/100      3.74G      1.025      1.317      1.293         27        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.0it/s 1:00<0.3ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.4it/s 28.6s0.1ss\n                   all       5823      15787      0.692      0.567       0.62      0.425\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     38/100      3.76G      1.015      1.305      1.292         18        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.0it/s 59.9s0.4ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.4it/s 28.3s0.1ss\n                   all       5823      15787      0.696       0.57      0.625      0.426\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     39/100      3.77G      1.008      1.291      1.287         43        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.0it/s 59.5s0.3ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.4it/s 28.6s0.1ss\n                   all       5823      15787      0.708      0.573      0.639       0.44\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     40/100      3.78G      1.011      1.281      1.287         25        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.0it/s 60.0s<0.1s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.4it/s 28.2s0.1ss\n                   all       5823      15787      0.695       0.57      0.628      0.432\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     41/100      3.79G     0.9988      1.263      1.279         32        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.0it/s 59.9s<0.1s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.4it/s 28.6s0.1ss\n                   all       5823      15787        0.7      0.583      0.638      0.442\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     42/100       3.8G      1.001      1.263      1.281         26        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.0it/s 59.9s<0.1s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.1it/s 30.0s0.1ss\n                   all       5823      15787      0.724      0.563      0.634      0.439\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     43/100      3.82G     0.9913      1.252      1.275          9        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.0it/s 59.5s<0.1s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.4it/s 28.6s0.2ss\n                   all       5823      15787      0.711      0.577      0.638       0.44\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     44/100      3.82G     0.9752       1.23      1.261         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.0it/s 59.8s0.3ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.4it/s 28.3s0.2ss\n                   all       5823      15787      0.724      0.584      0.648      0.451\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     45/100      3.84G     0.9841      1.234      1.268         26        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.0it/s 59.5s<0.1s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.4it/s 28.3s0.1ss\n                   all       5823      15787      0.711      0.586      0.641      0.446\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     46/100      3.85G       0.98      1.221      1.267         33        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.0it/s 59.7s0.3ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.5it/s 28.0s0.1ss\n                   all       5823      15787      0.731      0.577      0.644      0.446\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     47/100      3.86G     0.9724      1.217      1.261         26        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.0it/s 1:00<0.1ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.5it/s 27.9s0.1ss\n                   all       5823      15787      0.722      0.581      0.643      0.448\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     48/100      3.88G     0.9674      1.206      1.255         19        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.0it/s 59.6s0.3ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.5it/s 28.0s0.1ss\n                   all       5823      15787      0.726      0.585      0.651      0.452\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     49/100      3.88G     0.9643      1.203      1.258         23        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.0it/s 59.3s0.3ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.6it/s 27.8s0.1ss\n                   all       5823      15787      0.708      0.593      0.644      0.448\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     50/100       3.9G     0.9578      1.184      1.251         24        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.1it/s 59.1s<0.1s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.5it/s 27.9s0.1ss\n                   all       5823      15787      0.725      0.587      0.651      0.454\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     51/100       3.9G     0.9585      1.182       1.25         31        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.0it/s 59.2s0.3ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.5it/s 28.1s0.1ss\n                   all       5823      15787      0.719      0.596      0.657      0.454\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     52/100      3.92G     0.9535      1.158      1.249         36        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.0it/s 59.2s0.3ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.6it/s 27.6s0.1ss\n                   all       5823      15787       0.73      0.596       0.66      0.463\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     53/100      3.93G     0.9493      1.162       1.24         27        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.0it/s 59.6s<0.1s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.4it/s 28.4s0.1ss\n                   all       5823      15787      0.732      0.598      0.664      0.464\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     54/100      3.94G     0.9459      1.139      1.243         22        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.0it/s 1:00<0.3ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.4it/s 28.3s0.1ss\n                   all       5823      15787      0.731      0.592       0.66      0.461\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     55/100      3.95G     0.9402      1.142      1.241         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.0it/s 59.9s<0.1s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.5it/s 28.1s0.2ss\n                   all       5823      15787      0.737      0.601      0.666      0.469\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     56/100      3.96G     0.9407       1.13      1.232         33        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 5.9it/s 1:000.3sss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.4it/s 28.2s0.1ss\n                   all       5823      15787      0.736      0.602      0.665       0.47\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     57/100      3.97G     0.9311      1.116      1.232         55        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.0it/s 1:00<0.1ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.5it/s 28.0s0.1ss\n                   all       5823      15787      0.741      0.605      0.668      0.471\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     58/100      3.99G     0.9277      1.106      1.226         22        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.0it/s 59.9s0.3ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.4it/s 28.4s0.1ss\n                   all       5823      15787      0.737      0.591      0.661      0.465\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     59/100         4G     0.9294      1.089      1.227         28        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.0it/s 59.8s0.3ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.4it/s 28.3s0.1ss\n                   all       5823      15787      0.746      0.598      0.666      0.469\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     60/100      4.01G     0.9281      1.088      1.224         22        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.0it/s 59.6s0.3ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.4it/s 28.3s0.1ss\n                   all       5823      15787      0.748      0.601      0.671      0.473\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     61/100      4.02G     0.9178      1.075      1.219         27        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.0it/s 59.9s<0.1s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.4it/s 28.2s0.1ss\n                   all       5823      15787       0.76      0.595      0.671      0.476\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     62/100      4.03G     0.9153      1.072      1.217         28        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.0it/s 59.9s0.3ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.5it/s 28.0s0.1ss\n                   all       5823      15787      0.749        0.6      0.671      0.474\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     63/100      4.04G     0.9086      1.067      1.211         31        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.0it/s 59.8s<0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.4it/s 28.3s0.1ss\n                   all       5823      15787      0.729      0.613      0.672      0.477\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     64/100      4.05G     0.9021      1.065       1.21         23        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.0it/s 1:000.3sss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.4it/s 28.5s0.1ss\n                   all       5823      15787      0.745      0.605       0.67      0.476\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     65/100      4.06G     0.9053      1.047      1.208         35        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.0it/s 59.4s0.3ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.6it/s 27.7s0.1ss\n                   all       5823      15787       0.74      0.608      0.674      0.478\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     66/100      4.08G     0.8912      1.035      1.199         41        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.0it/s 59.3s0.3ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.5it/s 27.8s0.1ss\n                   all       5823      15787      0.762      0.603      0.677      0.483\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     67/100      4.09G      0.894      1.036      1.201         30        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.0it/s 59.6s0.3ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.5it/s 27.8s0.1ss\n                   all       5823      15787      0.749      0.612      0.674       0.48\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     68/100       4.1G     0.8938      1.023      1.199         19        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.0it/s 59.3s0.3ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.5it/s 28.1s0.1ss\n                   all       5823      15787      0.751      0.613      0.676      0.481\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     69/100      4.11G     0.8919      1.015      1.198         30        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.0it/s 59.6s<0.1s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.6it/s 27.6s0.1ss\n                   all       5823      15787      0.757      0.605      0.679      0.482\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     70/100      4.12G     0.8863       1.01      1.198         26        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.0it/s 59.4s0.3ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.6it/s 27.6s0.1ss\n                   all       5823      15787      0.756      0.615      0.682      0.487\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     71/100      4.13G     0.8816      1.018      1.193         28        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.0it/s 59.3s0.3ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.6it/s 27.8s0.1ss\n                   all       5823      15787      0.753      0.612      0.681      0.485\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     72/100      4.14G     0.8737     0.9979      1.189         21        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.0it/s 59.2s0.3ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.6it/s 27.6s0.1ss\n                   all       5823      15787      0.755      0.612      0.682      0.485\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     73/100      4.16G     0.8643     0.9782      1.183         33        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.0it/s 59.5s0.3ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.6it/s 27.5s0.1ss\n                   all       5823      15787      0.752      0.615      0.684      0.487\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     74/100      4.17G     0.8794     0.9838      1.187         22        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.0it/s 59.4s0.3ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.6it/s 27.4s0.1ss\n                   all       5823      15787      0.747      0.617      0.678      0.486\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     75/100      4.18G     0.8616     0.9749       1.18         40        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.0it/s 59.3s<0.1s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.4it/s 28.5s0.1ss\n                   all       5823      15787      0.752      0.614      0.684       0.49\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     76/100      4.19G     0.8653     0.9782       1.18         34        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 5.9it/s 1:000.3sss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.4it/s 28.4s0.1ss\n                   all       5823      15787      0.759      0.618      0.683      0.488\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     77/100       4.2G     0.8596     0.9578      1.179         34        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.0it/s 59.8s0.3ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.5it/s 28.2s0.1ss\n                   all       5823      15787       0.76      0.615      0.683      0.488\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     78/100      4.21G     0.8597     0.9597      1.176         20        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 5.9it/s 1:000.3sss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.5it/s 28.1s0.1ss\n                   all       5823      15787      0.764      0.608      0.681      0.487\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     79/100      4.22G     0.8538     0.9492      1.174         25        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.0it/s 1:00<0.2ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.5it/s 27.9s0.1ss\n                   all       5823      15787      0.748      0.616      0.684      0.488\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     80/100      4.24G     0.8513     0.9423      1.172         45        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 5.9it/s 1:010.3sss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.5it/s 28.1s0.1ss\n                   all       5823      15787      0.759      0.616      0.685      0.491\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     81/100      4.25G     0.8514     0.9394      1.173         46        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.0it/s 59.8s<0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.5it/s 28.0s0.1ss\n                   all       5823      15787       0.75       0.62      0.684      0.489\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     82/100      4.26G     0.8531     0.9383      1.171         39        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.0it/s 59.9s0.3ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.5it/s 28.0s0.1ss\n                   all       5823      15787      0.752      0.617      0.685      0.489\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     83/100      4.27G     0.8417     0.9152      1.158         46        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.0it/s 1:00<0.2ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.3it/s 28.8s0.2ss\n                   all       5823      15787       0.76      0.617      0.687      0.491\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     84/100      4.28G     0.8391     0.9123       1.16         62        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.0it/s 59.9s0.3ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.4it/s 28.6s0.1ss\n                   all       5823      15787       0.76      0.617      0.685      0.491\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     85/100      4.29G     0.8312      0.898      1.156         33        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 5.9it/s 1:00<0.1ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.4it/s 28.3s0.1ss\n                   all       5823      15787      0.754       0.62      0.688      0.494\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     86/100       4.3G     0.8224     0.8927      1.153         30        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 5.9it/s 1:000.3sss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.5it/s 28.0s0.1ss\n                   all       5823      15787      0.752      0.622      0.688      0.495\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     87/100      4.32G     0.8279     0.8973      1.154         20        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.0it/s 59.3s<0.1s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.6it/s 27.7s0.1ss\n                   all       5823      15787      0.757      0.621      0.687      0.494\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     88/100      4.33G     0.8266     0.8849       1.15         19        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.0it/s 59.3s0.3ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.6it/s 27.7s0.1ss\n                   all       5823      15787       0.75      0.624      0.687      0.493\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     89/100      4.34G     0.8194     0.8812      1.153         43        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.0it/s 59.3s<0.1s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.6it/s 27.7s0.1ss\n                   all       5823      15787      0.749      0.625      0.688      0.494\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     90/100      4.35G     0.8221      0.882      1.155         30        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.0it/s 59.6s0.3ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.6it/s 27.8s0.1ss\n                   all       5823      15787      0.758      0.625      0.689      0.494\nClosing dataloader mosaic\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     91/100      4.36G     0.7842     0.7346      1.124          9        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.0it/s 59.3s<0.1s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.6it/s 27.5s0.1ss\n                   all       5823      15787      0.752      0.616      0.681      0.488\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     92/100      4.38G     0.7687     0.6967      1.111         17        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.1it/s 58.3s0.3ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.6it/s 27.5s0.1ss\n                   all       5823      15787      0.754      0.619      0.681      0.488\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     93/100      4.38G     0.7608     0.6836      1.101         18        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.1it/s 58.3s<0.1s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.6it/s 27.7s0.1ss\n                   all       5823      15787      0.749      0.617       0.68      0.489\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     94/100       4.4G     0.7488     0.6669      1.091         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.1it/s 58.2s0.3ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.6it/s 27.5s0.1ss\n                   all       5823      15787      0.757      0.618      0.682      0.491\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     95/100      4.41G     0.7442     0.6634      1.088         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.2it/s 58.2s<0.1s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.6it/s 27.7s0.1ss\n                   all       5823      15787      0.757      0.618      0.684      0.492\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     96/100      4.42G     0.7398     0.6609      1.087          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.2it/s 58.0s0.3ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.6it/s 27.5s0.1ss\n                   all       5823      15787       0.77      0.613      0.686      0.493\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     97/100      4.43G     0.7338     0.6413      1.084         10        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.1it/s 58.3s<0.1s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.6it/s 27.8s0.1ss\n                   all       5823      15787      0.766      0.614      0.686      0.492\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     98/100      4.45G     0.7273     0.6396      1.082         14        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.1it/s 58.4s0.3ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.6it/s 27.6s0.1ss\n                   all       5823      15787      0.769      0.611      0.685      0.492\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     99/100      4.45G     0.7241     0.6339      1.076          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.2it/s 58.2s<0.1s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.6it/s 27.4s0.1ss\n                   all       5823      15787      0.772      0.608      0.685      0.492\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K    100/100      4.46G     0.7232     0.6314      1.075         24        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 358/358 6.1it/s 58.3s0.3ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.6it/s 27.6s0.1ss\n                   all       5823      15787      0.766      0.612      0.685      0.492\n\n100 epochs completed in 2.448 hours.\nOptimizer stripped from /kaggle/working/runs/train/yolo_voc/weights/last.pt, 6.2MB\nOptimizer stripped from /kaggle/working/runs/train/yolo_voc/weights/best.pt, 6.2MB\n\nValidating /kaggle/working/runs/train/yolo_voc/weights/best.pt...\nUltralytics 8.3.252 ðŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\nModel summary (fused): 72 layers, 3,009,548 parameters, 0 gradients, 8.1 GFLOPs\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 182/182 6.2it/s 29.2s0.1ss\n                   all       5823      15787      0.752      0.622      0.688      0.495\n             aeroplane        348        484      0.866      0.722      0.772      0.585\n               bicycle        290        380      0.771      0.703      0.761      0.553\n                  bird        374        629      0.746      0.563      0.633      0.427\n                  boat        252        491      0.612       0.47      0.538      0.323\n                bottle        369        733      0.734      0.438      0.517      0.338\n                   bus        211        320      0.866      0.744      0.805      0.674\n                   car        608       1173      0.829      0.625      0.733      0.518\n                   cat        544        618      0.793      0.788      0.851      0.651\n                 chair        642       1449      0.645       0.44      0.524      0.359\n                   cow        154        347      0.668      0.585      0.618      0.443\n           diningtable        323        374      0.696      0.521      0.588      0.402\n                   dog        661        773      0.781      0.727      0.787      0.602\n                 horse        245        373      0.762      0.705      0.772      0.578\n             motorbike        262        376      0.836      0.678      0.781      0.552\n                person       2232       5110      0.838      0.717      0.812      0.547\n           pottedplant        279        542      0.597      0.423      0.464      0.261\n                 sheep        155        485      0.754      0.645      0.697      0.516\n                  sofa        336        387      0.591      0.615      0.615      0.452\n                 train        275        329      0.857      0.729      0.816      0.617\n             tvmonitor        296        414      0.802      0.596      0.669      0.499\nSpeed: 0.1ms preprocess, 1.5ms inference, 0.0ms loss, 0.9ms postprocess per image\nResults saved to \u001b[1m/kaggle/working/runs/train/yolo_voc\u001b[0m\n\nâœ“ Training completed!\nBest model saved at: /kaggle/working/runs/train/yolo_voc/weights/best.pt\n\n======================================================================\nEVALUATING MODEL\n======================================================================\n\nUltralytics 8.3.252 ðŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\nModel summary (fused): 72 layers, 3,009,548 parameters, 0 gradients, 8.1 GFLOPs\n\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2059.9Â±222.1 MB/s, size: 170.9 KB)\n\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/voc_yolo_dataset/labels/val.cache... 5823 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5823/5823 2.4Git/s 0.0s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 364/364 9.3it/s 39.1ss<0.1s\n                   all       5823      15787      0.751      0.623      0.688      0.495\n             aeroplane        348        484      0.864      0.721      0.772      0.585\n               bicycle        290        380      0.773      0.703      0.761      0.554\n                  bird        374        629      0.743      0.566      0.633      0.428\n                  boat        252        491      0.613      0.473      0.537      0.322\n                bottle        369        733      0.732      0.438      0.519       0.34\n                   bus        211        320       0.86      0.748      0.806      0.672\n                   car        608       1173      0.829      0.625      0.734      0.518\n                   cat        544        618      0.795      0.788      0.852      0.651\n                 chair        642       1449      0.645      0.442      0.524      0.358\n                   cow        154        347      0.668      0.585      0.617      0.442\n           diningtable        323        374      0.697      0.521      0.588      0.403\n                   dog        661        773      0.782      0.727      0.787        0.6\n                 horse        245        373      0.757      0.705      0.772      0.577\n             motorbike        262        376      0.833      0.678      0.781      0.552\n                person       2232       5110      0.838      0.717      0.812      0.547\n           pottedplant        279        542      0.594      0.421      0.462       0.26\n                 sheep        155        485      0.752      0.643      0.697      0.516\n                  sofa        336        387      0.589      0.615      0.615      0.452\n                 train        275        329      0.855      0.733      0.816      0.618\n             tvmonitor        296        414      0.801      0.601      0.669      0.498\nSpeed: 0.6ms preprocess, 2.8ms inference, 0.0ms loss, 0.8ms postprocess per image\nResults saved to \u001b[1m/kaggle/working/runs/detect/val\u001b[0m\n\n======================================================================\nEVALUATION METRICS:\n======================================================================\nmAP50:       0.6877\nmAP50-95:    0.4946\nPrecision:   0.7510\nRecall:      0.6225\n======================================================================\n\n\n======================================================================\nTESTING INFERENCE\n======================================================================\n\nTesting on 5 sample images...\n\n\n0: 640x640 1 aeroplane, 7.7ms\n1: 640x640 3 cars, 7.7ms\n2: 640x640 2 chairs, 1 diningtable, 3 persons, 1 sofa, 7.7ms\n3: 640x640 2 dogs, 1 sofa, 7.7ms\n4: 640x640 2 persons, 7.7ms\nSpeed: 2.2ms preprocess, 7.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1m/kaggle/working/runs/detect/test\u001b[0m\n\nImage 1: 2010_005934.jpg\nDetections: 1\n  - aeroplane: 0.39\n\nImage 2: 2008_004414.jpg\nDetections: 3\n  - car: 0.90\n  - car: 0.67\n  - car: 0.66\n\nImage 3: 2008_001773.jpg\nDetections: 7\n  - person: 0.74\n  - chair: 0.65\n  - chair: 0.52\n  - diningtable: 0.49\n  - person: 0.35\n  - person: 0.34\n  - sofa: 0.28\n\nImage 4: 2010_006086.jpg\nDetections: 3\n  - sofa: 0.87\n  - dog: 0.87\n  - dog: 0.75\n\nImage 5: 2010_000474.jpg\nDetections: 2\n  - person: 0.96\n  - person: 0.88\n\nâœ“ Results saved to: /kaggle/working/runs/detect/test\n\n======================================================================\nEXPORTING MODEL\n======================================================================\n\nExporting to ONNX...\nUltralytics 8.3.252 ðŸš€ Python-3.12.12 torch-2.8.0+cu126 CPU (Intel Xeon CPU @ 2.00GHz)\nðŸ’¡ ProTip: Export to OpenVINO format for best performance on Intel hardware. Learn more at https://docs.ultralytics.com/integrations/openvino/\nModel summary (fused): 72 layers, 3,009,548 parameters, 0 gradients, 8.1 GFLOPs\n\n\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/kaggle/working/runs/train/yolo_voc/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 24, 8400) (6.0 MB)\n\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['onnxslim>=0.1.71', 'onnxruntime-gpu'] not found, attempting AutoUpdate...\nUsing Python 3.12.12 environment at: /usr\nResolved 14 packages in 282ms\nPrepared 4 packages in 3.37s\nInstalled 4 packages in 10ms\n + coloredlogs==15.0.1\n + humanfriendly==10.0\n + onnxruntime-gpu==1.23.2\n + onnxslim==0.1.82\n\n\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success âœ… 4.1s\nWARNING âš ï¸ \u001b[31m\u001b[1mrequirements:\u001b[0m \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n\n\n\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.20.0 opset 22...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/onnx/utils.py:1397: OnnxExporterWarning: Exporting to ONNX opset version 22 is not supported. by 'torch.onnx.export()'. The highest opset version supported is 20. To use a newer opset version, consider 'torch.onnx.export(..., dynamo=True)'. \n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.82...\n\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 5.4s, saved as '/kaggle/working/runs/train/yolo_voc/weights/best.onnx' (11.7 MB)\n\nExport complete (5.7s)\nResults saved to \u001b[1m/kaggle/working/runs/train/yolo_voc/weights\u001b[0m\nPredict:         yolo predict task=detect model=/kaggle/working/runs/train/yolo_voc/weights/best.onnx imgsz=640  \nValidate:        yolo val task=detect model=/kaggle/working/runs/train/yolo_voc/weights/best.onnx imgsz=640 data=/kaggle/working/voc.yaml  \nVisualize:       https://netron.app\nâœ“ ONNX model: /kaggle/working/runs/train/yolo_voc/weights/best.onnx\n\nâœ“ Model export completed!\n\n======================================================================\nPIPELINE COMPLETED SUCCESSFULLY!\n======================================================================\n\nTrained model: /kaggle/working/runs/train/yolo_voc/weights/best.pt\nResults directory: /kaggle/working/runs\n\nTo download trained model, use:\n  from IPython.display import FileLink\n  FileLink('/kaggle/working/runs/train/yolo_voc/weights/best.pt')\n","output_type":"stream"}],"execution_count":6}]}